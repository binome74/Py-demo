> Необходимо:
> 
> 1. Написать скрипт на Python который загружает в БД (sqlite3) данные по каждому твиту из файла “three_minutes_tweets.json.txt”:
> структура твита: name, tweet_text, country_code, display_url, lang, created_at, location
> 
> 2. Для каждого твита в базе необходимо завести атрибут с эмоциональной оценкой сообщения: tweet_sentiment
> 
> 3. Подумать как можно нормализовать хранение твита (привести SQL-скрипты создания/изменения нормализованной структуры данных)

П.п. 1, 2 и 3 сделаны сразу:
- скрипт 00_Create_database.sql поадется на вход sqlite3.exe
```
sqlite3.exe < 00_Create_database.sql
```
- скрипт 01_Extract.py загружает данные в БД

Так как location из списка user - поле произвольного ввода, то оно для ответа на последующий запрос "вывести наиболее и наименее счастливую локацию" не подходит. Тогда берем поле name из списка place. Отсюда имеем очевидную функциональную зависимость place -> country_code, которую и выносим в отдельную таблицу (справочник). Далее, display_url может относиться к ссылкам, которые публикует пользователь, так и к ссылкам на опубликованное пользователем медиа. Это всё к твиту относится как 1:M, поэтому также выносим в отдельную дочернюю таблицу. Других зависимостей, которые бы нуждались в нормализации, на таблице твитов нет.

> 4. Написать скрипт на Python для подсчета среднего sentiment (Эмоциональной окраски сообщения) на основе AFINN-111.txt 
> и заполнить  для каждого твита tweet_sentiment колонку. 
> Если твит не содержит слов из словаря то предполагать что sentiment =0
> AFINN ReadMe:
> AFINN is a list of English words rated for valence with an integer
> between minus five (negative) and plus five (positive). The words have
> been manually labeled by Finn Arup Nielsen in 2009-2011. The file
> is tab-separated. There are two versions:
> AFINN-111: Newest version with 2477 words and phrases.

См. скрипт 02_Sentiment.py.

> 5. Написать SQL скрипт, который выводит наиболее и наименее счастливую страну, локацию и пользователя 
> (дял пользователя - вместе с его твитами), предоставить сами скрипты и результаты их работы.

См. скрипты 03_Happy-Grumpy-Loc.sql, 04_Happy-Grumpy-Country.sql, 05_Happy-Grumpy-User.sql.
Скрипт 06_CHECK_Happy-Grumpy-User.sql также является корректным решением (в разрезе пользователя), использовался для контроля корректности результатов, возвращаемых другой версией.

> 6. Описать свое видение решения, которое позволит выполнять ежедневно анализ согласно п.5. Из каких компонентов должно 
> состоять решение, из каких шагов должен состоять ETL процесс от обработки входящих файлов до этапа сохранения конечной
> информации.
> - на входе - непрерывный поток на FTP твитов в файлах (tweet.json), с частотой каждые три минуты. 
> Размеры файлов - в среднем x10 от предоставленного сэмпла.
> - на выходе - пользователи должны иметь возможность анализировать счастье по странам, локациям, пользователям, 
> отслеживать изменения, собирать статиcтику и т.д. 

